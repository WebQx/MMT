# Heavy ML stack (installed only when include_ml=true in CI)
# Pin torch explicitly to avoid resolver backtracking selecting many CUDA builds.
torch==2.3.1
openai-whisper==20231117
presidio-analyzer==2.2.354